{"version":3,"file":"vercel_kv.js","names":[],"sources":["../../src/caches/vercel_kv.ts"],"sourcesContent":["import { kv, type VercelKV } from \"@vercel/kv\";\n\nimport { Generation } from \"@langchain/core/outputs\";\nimport {\n  BaseCache,\n  deserializeStoredGeneration,\n  serializeGeneration,\n} from \"@langchain/core/caches\";\nimport { StoredGeneration } from \"@langchain/core/messages\";\n\nexport type VercelKVCacheProps = {\n  /**\n   * An existing Vercel KV client\n   */\n  client?: VercelKV;\n  /**\n   * Time-to-live (TTL) for cached items in seconds\n   */\n  ttl?: number;\n};\n\n/**\n * A cache that uses Vercel KV as the backing store.\n * @example\n * ```typescript\n * const cache = new VercelKVCache({\n *   ttl: 3600, // Optional: Cache entries will expire after 1 hour\n * });\n *\n * // Initialize the OpenAI model with Vercel KV cache for caching responses\n * const model = new ChatOpenAI({\n *   model: \"gpt-4o-mini\",\n *   cache,\n * });\n * await model.invoke(\"How are you today?\");\n * const cachedValues = await cache.lookup(\"How are you today?\", \"llmKey\");\n * ```\n */\nexport class VercelKVCache extends BaseCache {\n  private client: VercelKV;\n\n  private ttl?: number;\n\n  constructor(props: VercelKVCacheProps) {\n    super();\n    const { client, ttl } = props;\n    this.client = client ?? kv;\n    this.ttl = ttl;\n  }\n\n  /**\n   * Lookup LLM generations in cache by prompt and associated LLM key.\n   */\n  public async lookup(prompt: string, llmKey: string) {\n    let idx = 0;\n    let key = this.keyEncoder(prompt, llmKey, String(idx));\n    let value = await this.client.get<StoredGeneration | null>(key);\n    const generations: Generation[] = [];\n\n    while (value) {\n      generations.push(deserializeStoredGeneration(value));\n      idx += 1;\n      key = this.keyEncoder(prompt, llmKey, String(idx));\n      value = await this.client.get<StoredGeneration | null>(key);\n    }\n\n    return generations.length > 0 ? generations : null;\n  }\n\n  /**\n   * Update the cache with the given generations.\n   *\n   * Note this overwrites any existing generations for the given prompt and LLM key.\n   */\n  public async update(prompt: string, llmKey: string, value: Generation[]) {\n    for (let i = 0; i < value.length; i += 1) {\n      const key = this.keyEncoder(prompt, llmKey, String(i));\n      const serializedValue = JSON.stringify(serializeGeneration(value[i]));\n\n      if (this.ttl) {\n        await this.client.set(key, serializedValue, { ex: this.ttl });\n      } else {\n        await this.client.set(key, serializedValue);\n      }\n    }\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;AAsCA,IAAa,gBAAb,cAAmC,UAAU;CAC3C,AAAQ;CAER,AAAQ;CAER,YAAY,OAA2B;AACrC,SAAO;EACP,MAAM,EAAE,QAAQ,QAAQ;AACxB,OAAK,SAAS,UAAU;AACxB,OAAK,MAAM;;;;;CAMb,MAAa,OAAO,QAAgB,QAAgB;EAClD,IAAI,MAAM;EACV,IAAI,MAAM,KAAK,WAAW,QAAQ,QAAQ,OAAO,IAAI,CAAC;EACtD,IAAI,QAAQ,MAAM,KAAK,OAAO,IAA6B,IAAI;EAC/D,MAAM,cAA4B,EAAE;AAEpC,SAAO,OAAO;AACZ,eAAY,KAAK,4BAA4B,MAAM,CAAC;AACpD,UAAO;AACP,SAAM,KAAK,WAAW,QAAQ,QAAQ,OAAO,IAAI,CAAC;AAClD,WAAQ,MAAM,KAAK,OAAO,IAA6B,IAAI;;AAG7D,SAAO,YAAY,SAAS,IAAI,cAAc;;;;;;;CAQhD,MAAa,OAAO,QAAgB,QAAgB,OAAqB;AACvE,OAAK,IAAI,IAAI,GAAG,IAAI,MAAM,QAAQ,KAAK,GAAG;GACxC,MAAM,MAAM,KAAK,WAAW,QAAQ,QAAQ,OAAO,EAAE,CAAC;GACtD,MAAM,kBAAkB,KAAK,UAAU,oBAAoB,MAAM,GAAG,CAAC;AAErE,OAAI,KAAK,IACP,OAAM,KAAK,OAAO,IAAI,KAAK,iBAAiB,EAAE,IAAI,KAAK,KAAK,CAAC;OAE7D,OAAM,KAAK,OAAO,IAAI,KAAK,gBAAgB"}