{"version":3,"file":"ibm.js","names":[],"sources":["../../src/llms/ibm.ts"],"sourcesContent":["import { CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nimport { BaseLLM, BaseLLMParams } from \"@langchain/core/language_models/llms\";\nimport { Stream, WatsonXAI } from \"@ibm-cloud/watsonx-ai\";\nimport {\n  RequestCallbacks,\n  ReturnOptionProperties,\n  TextGenLengthPenalty,\n  TextGenParameters,\n  TextTokenizationParams,\n  TextTokenizeParameters,\n} from \"@ibm-cloud/watsonx-ai/dist/watsonx-ai-ml/vml_v1.js\";\nimport {\n  Generation,\n  LLMResult,\n  GenerationChunk,\n} from \"@langchain/core/outputs\";\nimport { BaseLanguageModelCallOptions } from \"@langchain/core/language_models/base\";\nimport { AsyncCaller } from \"@langchain/core/utils/async_caller\";\nimport {\n  CreateCompletionsParams,\n  Gateway,\n  TextCompletionStream,\n} from \"@ibm-cloud/watsonx-ai/gateway\";\nimport {\n  authenticateAndSetGatewayInstance,\n  authenticateAndSetInstance,\n  checkValidProps,\n  expectOneOf,\n} from \"../utils/ibm.js\";\nimport {\n  GenerationInfo,\n  ResponseChunk,\n  TokenUsage,\n  WatsonxAuth,\n  WatsonxInit,\n  WatsonxLLMBasicOptions,\n  XOR,\n} from \"../types/ibm.js\";\n\n/**\n * Input to LLM class.\n */\n\n/** Parameters for basic llm invoke */\nexport interface WatsonxLLMParams {\n  maxNewTokens?: number;\n  maxTokens?: number;\n  decodingMethod?: TextGenParameters.Constants.DecodingMethod | string;\n  lengthPenalty?: TextGenLengthPenalty;\n  minNewTokens?: number;\n  randomSeed?: number;\n  stopSequence?: string[];\n  temperature?: number;\n  timeLimit?: number;\n  topK?: number;\n  topP?: number;\n  repetitionPenalty?: number;\n  truncateInputTokens?: number;\n  returnOptions?: ReturnOptionProperties;\n  includeStopSequence?: boolean;\n  // eslint-disable-next-line @typescript-eslint/no-explicit-any\n  headers?: Record<string, any>;\n  signal?: AbortSignal;\n}\n/** Parameters for basic llm invoke */\nexport interface WatsonxDeploymentLLMParams {\n  idOrName: string;\n}\n/** Gateway parameters */\n\ninterface WatsonxLLMGatewayKwargs extends Omit<\n  CreateCompletionsParams,\n  keyof WatsonxLLMParams | \"model\" | \"stream\" | \"prompt\" | \"maxTokens\"\n> {}\n\nexport interface WatsonxLLMGatewayParams\n  extends\n    WatsonxInit,\n    Omit<\n      CreateCompletionsParams,\n      keyof WatsonxLLMGatewayKwargs | \"stream\" | \"prompt\"\n    > {\n  /** Additional parameters usable only in model gateway */\n  modelGatewayKwargs?: WatsonxLLMGatewayKwargs;\n  modelGateway: boolean;\n}\n\n/** Call interface for second parameter of inbuild methods */\nexport interface WatsonxCallOptionsLLM\n  extends BaseLanguageModelCallOptions, Partial<WatsonxInit> {\n  maxRetries?: number;\n  parameters?: XOR<Partial<WatsonxLLMParams>, Partial<WatsonxLLMGatewayParams>>;\n  watsonxCallbacks?: RequestCallbacks;\n}\n\n/** Constructor input interfaces for each mode */\n\nexport interface WatsonxInputLLM\n  extends WatsonxLLMBasicOptions, WatsonxLLMParams {\n  model: string;\n  spaceId?: string;\n  projectId?: string;\n}\n\nexport interface WatsonxDeployedInputLLM\n  extends WatsonxLLMBasicOptions, WatsonxDeploymentLLMParams {}\n\nexport interface WatsonxGatewayInputLLM\n  extends WatsonxLLMBasicOptions, WatsonxLLMGatewayParams {}\n\n// Combined input for chat excluding each mode to not be present at the same time\nexport type WatsonxLLMConstructor = XOR<\n  XOR<WatsonxInputLLM, WatsonxDeployedInputLLM>,\n  WatsonxGatewayInputLLM\n> &\n  WatsonxAuth;\n\n/**\n * Integration with an LLM.\n */\nexport class WatsonxLLM<\n  CallOptions extends WatsonxCallOptionsLLM = WatsonxCallOptionsLLM,\n>\n  extends BaseLLM<CallOptions>\n  implements BaseLLMParams\n{\n  // Used for tracing, replace with the same name as your class\n  static lc_name() {\n    return \"WatsonxLLM\";\n  }\n\n  lc_serializable = true;\n\n  streaming = false;\n\n  model: string;\n\n  maxRetries = 0;\n\n  version = \"2024-05-31\";\n\n  serviceUrl: string;\n\n  maxTokens?: number;\n\n  maxNewTokens?: number;\n\n  spaceId?: string;\n\n  projectId?: string;\n\n  idOrName?: string;\n\n  decodingMethod?:\n    | WatsonXAI.TextGenParameters.Constants.DecodingMethod\n    | string;\n\n  lengthPenalty?: TextGenLengthPenalty;\n\n  minNewTokens?: number;\n\n  randomSeed?: number;\n\n  stopSequence?: string[];\n\n  temperature?: number;\n\n  timeLimit?: number;\n\n  topK?: number;\n\n  topP?: number;\n\n  repetitionPenalty?: number;\n\n  truncateInputTokens?: number;\n\n  returnOptions?: ReturnOptionProperties;\n\n  includeStopSequence?: boolean;\n\n  maxConcurrency?: number;\n\n  watsonxCallbacks?: RequestCallbacks;\n\n  modelGateway = false;\n\n  modelGatewayKwargs: WatsonxLLMGatewayKwargs = {};\n\n  protected service?: WatsonXAI;\n\n  protected gateway?: Gateway;\n\n  private checkValidProperties(\n    fields:\n      | WatsonxLLMConstructor\n      | XOR<Partial<WatsonxLLMParams>, Partial<WatsonxLLMGatewayParams>>,\n    includeCommonProps = true\n  ) {\n    const authProps = [\n      \"serviceUrl\",\n      \"watsonxAIApikey\",\n      \"watsonxAIBearerToken\",\n      \"watsonxAIUsername\",\n      \"watsonxAIPassword\",\n      \"watsonxAIUrl\",\n      \"watsonxAIAuthType\",\n      \"disableSSL\",\n    ];\n\n    const sharedProps = [\n      \"maxRetries\",\n      \"watsonxCallbacks\",\n      \"authenticator\",\n      \"serviceUrl\",\n      \"version\",\n      \"streaming\",\n      \"callbackManager\",\n      \"callbacks\",\n      \"maxConcurrency\",\n      \"cache\",\n      \"metadata\",\n      \"concurrency\",\n      \"onFailedAttempt\",\n      \"concurrency\",\n      \"verbose\",\n      \"tags\",\n    ];\n\n    const gatewayProps = [\n      \"temperature\",\n      \"topP\",\n      \"model\",\n      \"modelGatewayKwargs\",\n      \"modelGateway\",\n      \"verbose\",\n      \"tags\",\n      \"maxTokens\",\n    ];\n\n    const deploymentProps = [\"idOrName\"];\n\n    const projectOrSpaceProps = [\n      \"spaceId\",\n      \"projectId\",\n      \"temperature\",\n      \"topP\",\n      \"timeLimit\",\n      \"model\",\n      \"maxNewTokens\",\n      \"decodingMethod\",\n      \"lengthPenalty\",\n      \"minNewTokens\",\n      \"randomSeed\",\n      \"stopSequence\",\n      \"topK\",\n      \"repetitionPenalty\",\n      \"truncateInputTokens\",\n      \"returnOptions\",\n      \"includeStopSequence\",\n    ];\n\n    const validProps: string[] = [];\n    if (includeCommonProps) validProps.push(...authProps, ...sharedProps);\n\n    if (this.modelGateway) {\n      validProps.push(...gatewayProps);\n    } else if (this.idOrName) {\n      validProps.push(...deploymentProps);\n    } else if (this.spaceId || this.projectId) {\n      validProps.push(...projectOrSpaceProps);\n    }\n    checkValidProps(fields, validProps);\n  }\n\n  constructor(fields: WatsonxLLMConstructor) {\n    super(fields);\n    expectOneOf(\n      fields,\n      [\"spaceId\", \"projectId\", \"idOrName\", \"modelGateway\"],\n      true\n    );\n    this.idOrName = fields?.idOrName;\n    this.projectId = fields?.projectId;\n    this.modelGateway = fields.modelGateway || this.modelGateway;\n    this.spaceId = fields?.spaceId;\n\n    this.checkValidProperties(fields);\n\n    this.model = fields.model ?? this.model;\n    this.serviceUrl = fields.serviceUrl;\n    this.version = fields.version;\n\n    this.topP = fields.topP;\n    this.temperature = fields.temperature;\n    this.maxNewTokens = fields.maxNewTokens ?? fields.maxTokens;\n    this.decodingMethod = fields.decodingMethod;\n    this.lengthPenalty = fields.lengthPenalty;\n    this.minNewTokens = fields.minNewTokens;\n    this.maxTokens = fields.maxTokens;\n    this.randomSeed = fields.randomSeed;\n    this.stopSequence = fields.stopSequence;\n    this.timeLimit = fields.timeLimit;\n    this.topK = fields.topK;\n    this.repetitionPenalty = fields.repetitionPenalty;\n    this.truncateInputTokens = fields.truncateInputTokens;\n    this.returnOptions = fields.returnOptions;\n    this.includeStopSequence = fields.includeStopSequence;\n\n    this.modelGatewayKwargs =\n      fields.modelGatewayKwargs || this.modelGatewayKwargs;\n\n    this.maxRetries = fields.maxRetries || this.maxRetries;\n    this.maxConcurrency = fields.maxConcurrency;\n    this.streaming = fields.streaming || this.streaming;\n    this.watsonxCallbacks = fields.watsonxCallbacks || this.watsonxCallbacks;\n\n    const {\n      watsonxAIApikey,\n      watsonxAIAuthType,\n      watsonxAIBearerToken,\n      watsonxAIUsername,\n      watsonxAIPassword,\n      watsonxAIUrl,\n      disableSSL,\n      version,\n      serviceUrl,\n    } = fields;\n\n    const authData = {\n      watsonxAIApikey,\n      watsonxAIAuthType,\n      watsonxAIBearerToken,\n      watsonxAIUsername,\n      watsonxAIPassword,\n      watsonxAIUrl,\n      disableSSL,\n      version,\n      serviceUrl,\n    };\n\n    if (this.modelGateway) {\n      const gateway = authenticateAndSetGatewayInstance(authData);\n\n      if (gateway) this.gateway = gateway;\n      else throw new Error(\"You have not provided any type of authentication\");\n    } else {\n      const service = authenticateAndSetInstance(authData);\n\n      if (service) this.service = service;\n      else throw new Error(\"You have not provided any type of authentication\");\n    }\n  }\n\n  get lc_secrets(): { [key: string]: string } {\n    return {\n      authenticator: \"AUTHENTICATOR\",\n      apiKey: \"WATSONX_AI_APIKEY\",\n      apikey: \"WATSONX_AI_APIKEY\",\n      watsonxAIAuthType: \"WATSONX_AI_AUTH_TYPE\",\n      watsonxAIApikey: \"WATSONX_AI_APIKEY\",\n      watsonxAIBearerToken: \"WATSONX_AI_BEARER_TOKEN\",\n      watsonxAIUsername: \"WATSONX_AI_USERNAME\",\n      watsonxAIPassword: \"WATSONX_AI_PASSWORD\",\n      watsonxAIUrl: \"WATSONX_AI_URL\",\n    };\n  }\n\n  get lc_aliases(): { [key: string]: string } {\n    return {\n      authenticator: \"authenticator\",\n      apikey: \"watsonx_ai_apikey\",\n      apiKey: \"watsonx_ai_apikey\",\n      watsonxAIAuthType: \"watsonx_ai_auth_type\",\n      watsonxAIApikey: \"watsonx_ai_apikey\",\n      watsonxAIBearerToken: \"watsonx_ai_bearer_token\",\n      watsonxAIUsername: \"watsonx_ai_username\",\n      watsonxAIPassword: \"watsonx_ai_password\",\n      watsonxAIUrl: \"watsonx_ai_url\",\n    };\n  }\n\n  invocationParams(options: this[\"ParsedCallOptions\"]) {\n    const { parameters } = options;\n    const { signal, maxRetries, maxConcurrency, timeout, ...rest } = options;\n    if (parameters) this.checkValidProperties(parameters, false);\n    if (this.idOrName && Object.keys(rest).length > 0)\n      throw new Error(\"Options cannot be provided to a deployed model\");\n    if (this.idOrName) return undefined;\n\n    if (this.modelGateway) {\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      const modelGatewayParams: Record<string, any> = {\n        ...this?.modelGatewayKwargs,\n        ...parameters?.modelGatewayKwargs,\n      };\n      return {\n        stop: options?.stop ?? this.stopSequence,\n        temperature: parameters?.temperature ?? this.temperature,\n        topP: parameters?.topP ?? this.topP,\n        maxTokens: parameters?.maxTokens ?? this.maxTokens,\n        ...modelGatewayParams,\n      };\n    }\n\n    return {\n      stop_sequences: options?.stop ?? this.stopSequence,\n      temperature: parameters?.temperature ?? this.temperature,\n      top_p: parameters?.topP ?? this.topP,\n      max_new_tokens:\n        parameters?.maxNewTokens ??\n        this.maxNewTokens ??\n        parameters?.maxTokens ??\n        this.maxTokens,\n      decoding_method: parameters?.decodingMethod ?? this.decodingMethod,\n      length_penalty: parameters?.lengthPenalty ?? this.lengthPenalty,\n      min_new_tokens: parameters?.minNewTokens ?? this.minNewTokens,\n      random_seed: parameters?.randomSeed ?? this.randomSeed,\n      time_limit: parameters?.timeLimit ?? this.timeLimit ?? timeout,\n      top_k: parameters?.topK ?? this.topK,\n      repetition_penalty:\n        parameters?.repetitionPenalty ?? this.repetitionPenalty,\n      truncate_input_tokens:\n        parameters?.truncateInputTokens ?? this.truncateInputTokens,\n      return_options: parameters?.returnOptions ?? this.returnOptions,\n      include_stop_sequence:\n        parameters?.includeStopSequence ?? this.includeStopSequence,\n    };\n  }\n\n  invocationCallbacks(options: this[\"ParsedCallOptions\"]) {\n    return options.watsonxCallbacks ?? this.watsonxCallbacks;\n  }\n\n  scopeId() {\n    if (this.projectId)\n      return { projectId: this.projectId, modelId: this.model };\n    else if (this.spaceId)\n      return { spaceId: this.spaceId, modelId: this.model };\n    else if (this.idOrName)\n      return { idOrName: this.idOrName, modelId: this.model };\n    else if (this.modelGateway) return { modelId: this.model };\n    else\n      throw new Error(\n        \"Invalid mode type. Please make sure you have provided correct parameters\"\n      );\n  }\n\n  async listModels() {\n    if (this.service) {\n      const { service } = this;\n      const listModelParams = {\n        filters: \"function_text_generation\",\n      };\n      const listModels = await this.completionWithRetry(() =>\n        service.listFoundationModelSpecs(listModelParams)\n      );\n      return listModels.result.resources?.map((item) => item.model_id);\n    } else {\n      throw new Error(\"This method is not supported in this model gateway\");\n    }\n  }\n\n  private async generateSingleMessage(\n    input: string,\n    options: this[\"ParsedCallOptions\"],\n    stream: true\n  ): Promise<\n    | Stream<WatsonXAI.ObjectStreamed<WatsonXAI.TextGenResponse>>\n    | Stream<TextCompletionStream>\n  >;\n\n  private async generateSingleMessage(\n    input: string,\n    options: this[\"ParsedCallOptions\"],\n    stream: false\n  ): Promise<Generation[]>;\n\n  private async generateSingleMessage(\n    input: string,\n    options: this[\"ParsedCallOptions\"],\n    stream: boolean\n  ) {\n    const {\n      signal,\n      stop,\n      maxRetries,\n      maxConcurrency,\n      timeout,\n      ...requestOptions\n    } = options;\n    const parameters = this.invocationParams(options);\n    const watsonxCallbacks = this.invocationCallbacks(options);\n\n    if (stream) {\n      if (this.service) {\n        if (this.idOrName) {\n          return await this.service.deploymentGenerateTextStream({\n            idOrName: this.idOrName,\n            ...requestOptions,\n            parameters: {\n              ...parameters,\n              prompt_variables: {\n                input,\n              },\n            },\n            returnObject: true,\n            signal,\n          });\n        } else {\n          return await this.service.generateTextStream(\n            {\n              input,\n              parameters,\n              ...this.scopeId(),\n              ...requestOptions,\n              returnObject: true,\n              signal,\n            },\n            watsonxCallbacks\n          );\n        }\n      } else if (this.gateway) {\n        return await this.gateway.completion.create({\n          ...parameters,\n          model: this.model,\n          prompt: input,\n          stream: true,\n          signal,\n          returnObject: true,\n        });\n      }\n    } else {\n      if (this.service) {\n        const tokenUsage = { generated_token_count: 0, input_token_count: 0 };\n\n        const textGenerationPromise = this.idOrName\n          ? this.service.deploymentGenerateText(\n              {\n                ...requestOptions,\n                idOrName: this.idOrName,\n                parameters: {\n                  ...parameters,\n                  prompt_variables: {\n                    input,\n                  },\n                },\n                signal,\n              },\n              watsonxCallbacks\n            )\n          : this.service.generateText(\n              {\n                input,\n                parameters,\n                ...this.scopeId(),\n                ...requestOptions,\n                signal,\n              },\n              watsonxCallbacks\n            );\n\n        const textGeneration = await textGenerationPromise;\n        const singleGeneration: Generation[] =\n          textGeneration.result.results.map((result) => {\n            tokenUsage.generated_token_count += result.generated_token_count\n              ? result.generated_token_count\n              : 0;\n            tokenUsage.input_token_count += result.input_token_count\n              ? result.input_token_count\n              : 0;\n            return {\n              text: result.generated_text,\n              generationInfo: {\n                stop_reason: result.stop_reason,\n                input_token_count: result.input_token_count,\n                generated_token_count: result.generated_token_count,\n              },\n            };\n          });\n        return singleGeneration;\n      } else if (this.gateway) {\n        const textGeneration = await this.gateway.completion.create({\n          ...parameters,\n          prompt: input,\n          model: this.model,\n          signal,\n        });\n        const tokenUsage = textGeneration.result.usage;\n        const singleGeneration: Generation[] =\n          textGeneration.result.choices.map((choice) => {\n            return {\n              text: choice.text ?? \"\",\n              generationInfo: {\n                stop_reason: choice.finish_reason,\n                input_token_count: tokenUsage?.prompt_tokens,\n                generated_token_count: tokenUsage?.completion_tokens,\n              },\n            };\n          });\n        return singleGeneration;\n      }\n    }\n    throw new Error(\n      \"No service or gateway set. Please check your intsance init\"\n    );\n  }\n\n  async completionWithRetry<T>(\n    callback: () => T,\n    options?: this[\"ParsedCallOptions\"]\n  ) {\n    const caller = new AsyncCaller({\n      maxConcurrency: options?.maxConcurrency || this.maxConcurrency,\n      maxRetries: this.maxRetries,\n    });\n    const result = options\n      ? caller.callWithOptions(\n          {\n            signal: options.signal,\n          },\n          async () => callback()\n        )\n      : caller.call(async () => callback());\n\n    return result;\n  }\n\n  async _generate(\n    prompts: string[],\n    options: this[\"ParsedCallOptions\"],\n    runManager?: CallbackManagerForLLMRun\n  ): Promise<LLMResult> {\n    const tokenUsage: TokenUsage = {\n      generated_token_count: 0,\n      input_token_count: 0,\n    };\n    if (this.streaming) {\n      const generations: Generation[][] = await Promise.all(\n        prompts.map(async (prompt, promptIdx) => {\n          const stream = this._streamResponseChunks(prompt, options);\n          const geneartionsArray: GenerationInfo[] = [];\n\n          for await (const chunk of stream) {\n            const completion = chunk?.generationInfo?.completion ?? 0;\n            const generationInfo: GenerationInfo = {\n              text: \"\",\n              stop_reason: \"\",\n              generated_token_count: 0,\n              input_token_count: 0,\n            };\n            geneartionsArray[completion] ??= generationInfo;\n            geneartionsArray[completion].generated_token_count =\n              chunk?.generationInfo?.usage_metadata.generated_token_count ?? 0;\n            geneartionsArray[completion].input_token_count +=\n              chunk?.generationInfo?.usage_metadata.input_token_count ?? 0;\n            geneartionsArray[completion].stop_reason =\n              chunk?.generationInfo?.stop_reason;\n            geneartionsArray[completion].text += chunk.text;\n            if (chunk.text)\n              // eslint-disable-next-line no-void\n              void runManager?.handleLLMNewToken(chunk.text, {\n                prompt: promptIdx,\n                completion: 0,\n              });\n          }\n\n          return geneartionsArray.map((item) => {\n            const { text, ...rest } = item;\n            tokenUsage.generated_token_count = rest.generated_token_count;\n            tokenUsage.input_token_count += rest.input_token_count;\n\n            return {\n              text,\n              generationInfo: rest,\n            };\n          });\n        })\n      );\n      const result: LLMResult = { generations, llmOutput: { tokenUsage } };\n      return result;\n    } else {\n      const generations: Generation[][] = await Promise.all(\n        prompts.map(async (prompt) => {\n          const callback = () =>\n            this.generateSingleMessage(prompt, options, false);\n          type ReturnMessage = ReturnType<typeof callback>;\n\n          const response = await this.completionWithRetry<ReturnMessage>(\n            callback,\n            options\n          );\n          const [generated_token_count, input_token_count] = response.reduce(\n            (acc, curr) => {\n              let generated = 0;\n              let inputed = 0;\n              if (curr?.generationInfo?.generated_token_count)\n                generated = curr.generationInfo.generated_token_count + acc[0];\n              if (curr?.generationInfo?.input_token_count)\n                inputed = curr.generationInfo.input_token_count + acc[1];\n              return [generated, inputed];\n            },\n            [0, 0]\n          );\n          tokenUsage.generated_token_count += generated_token_count;\n          tokenUsage.input_token_count += input_token_count;\n          return response;\n        })\n      );\n\n      const result: LLMResult = { generations, llmOutput: { tokenUsage } };\n      return result;\n    }\n  }\n\n  async getNumTokens(\n    content: string,\n    options?: TextTokenizeParameters\n  ): Promise<number> {\n    if (this.service) {\n      const { service } = this;\n      const params: TextTokenizationParams = {\n        ...this.scopeId(),\n        input: content,\n        parameters: options,\n      };\n      const callback = () => service.tokenizeText(params);\n      type ReturnTokens = ReturnType<typeof callback>;\n\n      const response = await this.completionWithRetry<ReturnTokens>(callback);\n      return response.result.result.token_count;\n    } else throw new Error(\"This method is not supported in model gateway\");\n  }\n\n  async *_streamResponseChunks(\n    prompt: string,\n    options: this[\"ParsedCallOptions\"],\n    runManager?: CallbackManagerForLLMRun\n  ): AsyncGenerator<GenerationChunk> {\n    const callback = () => this.generateSingleMessage(prompt, options, true);\n    type ReturnStream = ReturnType<typeof callback>;\n    const streamInferDeployedPrompt =\n      await this.completionWithRetry<ReturnStream>(callback);\n    const responseChunk: ResponseChunk = {\n      id: 0,\n      event: \"\",\n      data: {\n        results: [],\n      },\n    };\n    for await (const chunk of streamInferDeployedPrompt) {\n      const results =\n        \"model_id\" in chunk.data ? chunk.data.results : chunk.data.choices;\n\n      const usage = \"usage\" in chunk.data ? chunk.data.usage : {};\n      for (const [index, item] of results.entries()) {\n        const params =\n          \"generated_text\" in item\n            ? {\n                text: item.generated_text,\n                generationInfo: {\n                  stop_reason: item.stop_reason,\n                  completion: index,\n                  usage_metadata: {\n                    generated_token_count: item.generated_token_count,\n                    input_token_count: item.input_token_count,\n                    stop_reason: item.stop_reason,\n                  },\n                },\n              }\n            : {\n                text: item.text ?? \"\",\n                generationInfo: {\n                  stop_reason: item.finish_reason,\n                  completion: index,\n                  usage_metadata: {\n                    generated_token_count: usage?.completion_tokens,\n                    input_token_count: usage?.prompt_tokens,\n                    stop_reason: item.finish_reason,\n                  },\n                },\n              };\n        yield new GenerationChunk(params);\n        if (!this.streaming)\n          // eslint-disable-next-line no-void\n          void runManager?.handleLLMNewToken(\n            \"generated_text\" in item ? item.generated_text : (item.text ?? \"\")\n          );\n      }\n      Object.assign(responseChunk, { id: 0, event: \"\", data: {} });\n    }\n  }\n\n  _llmType() {\n    return \"watsonx\";\n  }\n}\n"],"mappings":";;;;;;;;;;;AAwHA,IAAa,aAAb,cAGU,QAEV;CAEE,OAAO,UAAU;AACf,SAAO;;CAGT,kBAAkB;CAElB,YAAY;CAEZ;CAEA,aAAa;CAEb,UAAU;CAEV;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAIA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA,eAAe;CAEf,qBAA8C,EAAE;CAEhD,AAAU;CAEV,AAAU;CAEV,AAAQ,qBACN,QAGA,qBAAqB,MACrB;EACA,MAAM,YAAY;GAChB;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACD;EAED,MAAM,cAAc;GAClB;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACD;EAED,MAAM,eAAe;GACnB;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACD;EAED,MAAM,kBAAkB,CAAC,WAAW;EAEpC,MAAM,sBAAsB;GAC1B;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACD;EAED,MAAM,aAAuB,EAAE;AAC/B,MAAI,mBAAoB,YAAW,KAAK,GAAG,WAAW,GAAG,YAAY;AAErE,MAAI,KAAK,aACP,YAAW,KAAK,GAAG,aAAa;WACvB,KAAK,SACd,YAAW,KAAK,GAAG,gBAAgB;WAC1B,KAAK,WAAW,KAAK,UAC9B,YAAW,KAAK,GAAG,oBAAoB;AAEzC,kBAAgB,QAAQ,WAAW;;CAGrC,YAAY,QAA+B;AACzC,QAAM,OAAO;AACb,cACE,QACA;GAAC;GAAW;GAAa;GAAY;GAAe,EACpD,KACD;AACD,OAAK,WAAW,QAAQ;AACxB,OAAK,YAAY,QAAQ;AACzB,OAAK,eAAe,OAAO,gBAAgB,KAAK;AAChD,OAAK,UAAU,QAAQ;AAEvB,OAAK,qBAAqB,OAAO;AAEjC,OAAK,QAAQ,OAAO,SAAS,KAAK;AAClC,OAAK,aAAa,OAAO;AACzB,OAAK,UAAU,OAAO;AAEtB,OAAK,OAAO,OAAO;AACnB,OAAK,cAAc,OAAO;AAC1B,OAAK,eAAe,OAAO,gBAAgB,OAAO;AAClD,OAAK,iBAAiB,OAAO;AAC7B,OAAK,gBAAgB,OAAO;AAC5B,OAAK,eAAe,OAAO;AAC3B,OAAK,YAAY,OAAO;AACxB,OAAK,aAAa,OAAO;AACzB,OAAK,eAAe,OAAO;AAC3B,OAAK,YAAY,OAAO;AACxB,OAAK,OAAO,OAAO;AACnB,OAAK,oBAAoB,OAAO;AAChC,OAAK,sBAAsB,OAAO;AAClC,OAAK,gBAAgB,OAAO;AAC5B,OAAK,sBAAsB,OAAO;AAElC,OAAK,qBACH,OAAO,sBAAsB,KAAK;AAEpC,OAAK,aAAa,OAAO,cAAc,KAAK;AAC5C,OAAK,iBAAiB,OAAO;AAC7B,OAAK,YAAY,OAAO,aAAa,KAAK;AAC1C,OAAK,mBAAmB,OAAO,oBAAoB,KAAK;EAExD,MAAM,EACJ,iBACA,mBACA,sBACA,mBACA,mBACA,cACA,YACA,SACA,eACE;EAEJ,MAAM,WAAW;GACf;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACA;GACD;AAED,MAAI,KAAK,cAAc;GACrB,MAAM,UAAU,kCAAkC,SAAS;AAE3D,OAAI,QAAS,MAAK,UAAU;OACvB,OAAM,IAAI,MAAM,mDAAmD;SACnE;GACL,MAAM,UAAU,2BAA2B,SAAS;AAEpD,OAAI,QAAS,MAAK,UAAU;OACvB,OAAM,IAAI,MAAM,mDAAmD;;;CAI5E,IAAI,aAAwC;AAC1C,SAAO;GACL,eAAe;GACf,QAAQ;GACR,QAAQ;GACR,mBAAmB;GACnB,iBAAiB;GACjB,sBAAsB;GACtB,mBAAmB;GACnB,mBAAmB;GACnB,cAAc;GACf;;CAGH,IAAI,aAAwC;AAC1C,SAAO;GACL,eAAe;GACf,QAAQ;GACR,QAAQ;GACR,mBAAmB;GACnB,iBAAiB;GACjB,sBAAsB;GACtB,mBAAmB;GACnB,mBAAmB;GACnB,cAAc;GACf;;CAGH,iBAAiB,SAAoC;EACnD,MAAM,EAAE,eAAe;EACvB,MAAM,EAAE,QAAQ,YAAY,gBAAgB,SAAS,GAAG,SAAS;AACjE,MAAI,WAAY,MAAK,qBAAqB,YAAY,MAAM;AAC5D,MAAI,KAAK,YAAY,OAAO,KAAK,KAAK,CAAC,SAAS,EAC9C,OAAM,IAAI,MAAM,iDAAiD;AACnE,MAAI,KAAK,SAAU,QAAO;AAE1B,MAAI,KAAK,cAAc;GAErB,MAAM,qBAA0C;IAC9C,GAAG,MAAM;IACT,GAAG,YAAY;IAChB;AACD,UAAO;IACL,MAAM,SAAS,QAAQ,KAAK;IAC5B,aAAa,YAAY,eAAe,KAAK;IAC7C,MAAM,YAAY,QAAQ,KAAK;IAC/B,WAAW,YAAY,aAAa,KAAK;IACzC,GAAG;IACJ;;AAGH,SAAO;GACL,gBAAgB,SAAS,QAAQ,KAAK;GACtC,aAAa,YAAY,eAAe,KAAK;GAC7C,OAAO,YAAY,QAAQ,KAAK;GAChC,gBACE,YAAY,gBACZ,KAAK,gBACL,YAAY,aACZ,KAAK;GACP,iBAAiB,YAAY,kBAAkB,KAAK;GACpD,gBAAgB,YAAY,iBAAiB,KAAK;GAClD,gBAAgB,YAAY,gBAAgB,KAAK;GACjD,aAAa,YAAY,cAAc,KAAK;GAC5C,YAAY,YAAY,aAAa,KAAK,aAAa;GACvD,OAAO,YAAY,QAAQ,KAAK;GAChC,oBACE,YAAY,qBAAqB,KAAK;GACxC,uBACE,YAAY,uBAAuB,KAAK;GAC1C,gBAAgB,YAAY,iBAAiB,KAAK;GAClD,uBACE,YAAY,uBAAuB,KAAK;GAC3C;;CAGH,oBAAoB,SAAoC;AACtD,SAAO,QAAQ,oBAAoB,KAAK;;CAG1C,UAAU;AACR,MAAI,KAAK,UACP,QAAO;GAAE,WAAW,KAAK;GAAW,SAAS,KAAK;GAAO;WAClD,KAAK,QACZ,QAAO;GAAE,SAAS,KAAK;GAAS,SAAS,KAAK;GAAO;WAC9C,KAAK,SACZ,QAAO;GAAE,UAAU,KAAK;GAAU,SAAS,KAAK;GAAO;WAChD,KAAK,aAAc,QAAO,EAAE,SAAS,KAAK,OAAO;MAExD,OAAM,IAAI,MACR,2EACD;;CAGL,MAAM,aAAa;AACjB,MAAI,KAAK,SAAS;GAChB,MAAM,EAAE,YAAY;GACpB,MAAM,kBAAkB,EACtB,SAAS,4BACV;AAID,WAHmB,MAAM,KAAK,0BAC5B,QAAQ,yBAAyB,gBAAgB,CAClD,EACiB,OAAO,WAAW,KAAK,SAAS,KAAK,SAAS;QAEhE,OAAM,IAAI,MAAM,qDAAqD;;CAmBzE,MAAc,sBACZ,OACA,SACA,QACA;EACA,MAAM,EACJ,QACA,MACA,YACA,gBACA,SACA,GAAG,mBACD;EACJ,MAAM,aAAa,KAAK,iBAAiB,QAAQ;EACjD,MAAM,mBAAmB,KAAK,oBAAoB,QAAQ;AAE1D,MAAI,QACF;OAAI,KAAK,QACP,KAAI,KAAK,SACP,QAAO,MAAM,KAAK,QAAQ,6BAA6B;IACrD,UAAU,KAAK;IACf,GAAG;IACH,YAAY;KACV,GAAG;KACH,kBAAkB,EAChB,OACD;KACF;IACD,cAAc;IACd;IACD,CAAC;OAEF,QAAO,MAAM,KAAK,QAAQ,mBACxB;IACE;IACA;IACA,GAAG,KAAK,SAAS;IACjB,GAAG;IACH,cAAc;IACd;IACD,EACD,iBACD;YAEM,KAAK,QACd,QAAO,MAAM,KAAK,QAAQ,WAAW,OAAO;IAC1C,GAAG;IACH,OAAO,KAAK;IACZ,QAAQ;IACR,QAAQ;IACR;IACA,cAAc;IACf,CAAC;aAGA,KAAK,SAAS;GAChB,MAAM,aAAa;IAAE,uBAAuB;IAAG,mBAAmB;IAAG;AA8CrE,WAlBuB,OA1BO,KAAK,WAC/B,KAAK,QAAQ,uBACX;IACE,GAAG;IACH,UAAU,KAAK;IACf,YAAY;KACV,GAAG;KACH,kBAAkB,EAChB,OACD;KACF;IACD;IACD,EACD,iBACD,GACD,KAAK,QAAQ,aACX;IACE;IACA;IACA,GAAG,KAAK,SAAS;IACjB,GAAG;IACH;IACD,EACD,iBACD,GAIY,OAAO,QAAQ,KAAK,WAAW;AAC5C,eAAW,yBAAyB,OAAO,wBACvC,OAAO,wBACP;AACJ,eAAW,qBAAqB,OAAO,oBACnC,OAAO,oBACP;AACJ,WAAO;KACL,MAAM,OAAO;KACb,gBAAgB;MACd,aAAa,OAAO;MACpB,mBAAmB,OAAO;MAC1B,uBAAuB,OAAO;MAC/B;KACF;KACD;aAEK,KAAK,SAAS;GACvB,MAAM,iBAAiB,MAAM,KAAK,QAAQ,WAAW,OAAO;IAC1D,GAAG;IACH,QAAQ;IACR,OAAO,KAAK;IACZ;IACD,CAAC;GACF,MAAM,aAAa,eAAe,OAAO;AAYzC,UAVE,eAAe,OAAO,QAAQ,KAAK,WAAW;AAC5C,WAAO;KACL,MAAM,OAAO,QAAQ;KACrB,gBAAgB;MACd,aAAa,OAAO;MACpB,mBAAmB,YAAY;MAC/B,uBAAuB,YAAY;MACpC;KACF;KACD;;AAIR,QAAM,IAAI,MACR,6DACD;;CAGH,MAAM,oBACJ,UACA,SACA;EACA,MAAM,SAAS,IAAI,YAAY;GAC7B,gBAAgB,SAAS,kBAAkB,KAAK;GAChD,YAAY,KAAK;GAClB,CAAC;AAUF,SATe,UACX,OAAO,gBACL,EACE,QAAQ,QAAQ,QACjB,EACD,YAAY,UAAU,CACvB,GACD,OAAO,KAAK,YAAY,UAAU,CAAC;;CAKzC,MAAM,UACJ,SACA,SACA,YACoB;EACpB,MAAM,aAAyB;GAC7B,uBAAuB;GACvB,mBAAmB;GACpB;AACD,MAAI,KAAK,UA2CP,QAD0B;GAAE,aAzCQ,MAAM,QAAQ,IAChD,QAAQ,IAAI,OAAO,QAAQ,cAAc;IACvC,MAAM,SAAS,KAAK,sBAAsB,QAAQ,QAAQ;IAC1D,MAAM,mBAAqC,EAAE;AAE7C,eAAW,MAAM,SAAS,QAAQ;KAChC,MAAM,aAAa,OAAO,gBAAgB,cAAc;AAOxD,sBAAiB,gBANsB;MACrC,MAAM;MACN,aAAa;MACb,uBAAuB;MACvB,mBAAmB;MACpB;AAED,sBAAiB,YAAY,wBAC3B,OAAO,gBAAgB,eAAe,yBAAyB;AACjE,sBAAiB,YAAY,qBAC3B,OAAO,gBAAgB,eAAe,qBAAqB;AAC7D,sBAAiB,YAAY,cAC3B,OAAO,gBAAgB;AACzB,sBAAiB,YAAY,QAAQ,MAAM;AAC3C,SAAI,MAAM,KAER,CAAK,YAAY,kBAAkB,MAAM,MAAM;MAC7C,QAAQ;MACR,YAAY;MACb,CAAC;;AAGN,WAAO,iBAAiB,KAAK,SAAS;KACpC,MAAM,EAAE,MAAM,GAAG,SAAS;AAC1B,gBAAW,wBAAwB,KAAK;AACxC,gBAAW,qBAAqB,KAAK;AAErC,YAAO;MACL;MACA,gBAAgB;MACjB;MACD;KACF,CACH;GACwC,WAAW,EAAE,YAAY;GAAE;MAgCpE,QAD0B;GAAE,aA5BQ,MAAM,QAAQ,IAChD,QAAQ,IAAI,OAAO,WAAW;IAC5B,MAAM,iBACJ,KAAK,sBAAsB,QAAQ,SAAS,MAAM;IAGpD,MAAM,WAAW,MAAM,KAAK,oBAC1B,UACA,QACD;IACD,MAAM,CAAC,uBAAuB,qBAAqB,SAAS,QACzD,KAAK,SAAS;KACb,IAAI,YAAY;KAChB,IAAI,UAAU;AACd,SAAI,MAAM,gBAAgB,sBACxB,aAAY,KAAK,eAAe,wBAAwB,IAAI;AAC9D,SAAI,MAAM,gBAAgB,kBACxB,WAAU,KAAK,eAAe,oBAAoB,IAAI;AACxD,YAAO,CAAC,WAAW,QAAQ;OAE7B,CAAC,GAAG,EAAE,CACP;AACD,eAAW,yBAAyB;AACpC,eAAW,qBAAqB;AAChC,WAAO;KACP,CACH;GAEwC,WAAW,EAAE,YAAY;GAAE;;CAKxE,MAAM,aACJ,SACA,SACiB;AACjB,MAAI,KAAK,SAAS;GAChB,MAAM,EAAE,YAAY;GACpB,MAAM,SAAiC;IACrC,GAAG,KAAK,SAAS;IACjB,OAAO;IACP,YAAY;IACb;GACD,MAAM,iBAAiB,QAAQ,aAAa,OAAO;AAInD,WADiB,MAAM,KAAK,oBAAkC,SAAS,EACvD,OAAO,OAAO;QACzB,OAAM,IAAI,MAAM,gDAAgD;;CAGzE,OAAO,sBACL,QACA,SACA,YACiC;EACjC,MAAM,iBAAiB,KAAK,sBAAsB,QAAQ,SAAS,KAAK;EAExE,MAAM,4BACJ,MAAM,KAAK,oBAAkC,SAAS;EACxD,MAAM,gBAA+B;GACnC,IAAI;GACJ,OAAO;GACP,MAAM,EACJ,SAAS,EAAE,EACZ;GACF;AACD,aAAW,MAAM,SAAS,2BAA2B;GACnD,MAAM,UACJ,cAAc,MAAM,OAAO,MAAM,KAAK,UAAU,MAAM,KAAK;GAE7D,MAAM,QAAQ,WAAW,MAAM,OAAO,MAAM,KAAK,QAAQ,EAAE;AAC3D,QAAK,MAAM,CAAC,OAAO,SAAS,QAAQ,SAAS,EAAE;AA2B7C,UAAM,IAAI,gBAzBR,oBAAoB,OAChB;KACE,MAAM,KAAK;KACX,gBAAgB;MACd,aAAa,KAAK;MAClB,YAAY;MACZ,gBAAgB;OACd,uBAAuB,KAAK;OAC5B,mBAAmB,KAAK;OACxB,aAAa,KAAK;OACnB;MACF;KACF,GACD;KACE,MAAM,KAAK,QAAQ;KACnB,gBAAgB;MACd,aAAa,KAAK;MAClB,YAAY;MACZ,gBAAgB;OACd,uBAAuB,OAAO;OAC9B,mBAAmB,OAAO;OAC1B,aAAa,KAAK;OACnB;MACF;KACF,CAC0B;AACjC,QAAI,CAAC,KAAK,UAER,CAAK,YAAY,kBACf,oBAAoB,OAAO,KAAK,iBAAkB,KAAK,QAAQ,GAChE;;AAEL,UAAO,OAAO,eAAe;IAAE,IAAI;IAAG,OAAO;IAAI,MAAM,EAAE;IAAE,CAAC;;;CAIhE,WAAW;AACT,SAAO"}