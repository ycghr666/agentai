{"version":3,"file":"moonshot.js","names":[],"sources":["../../src/chat_models/moonshot.ts"],"sourcesContent":["import {\n  BaseChatModel,\n  type BaseChatModelParams,\n} from \"@langchain/core/language_models/chat_models\";\nimport {\n  AIMessage,\n  type BaseMessage,\n  ChatMessage,\n} from \"@langchain/core/messages\";\nimport { type ChatResult } from \"@langchain/core/outputs\";\nimport { type CallbackManagerForLLMRun } from \"@langchain/core/callbacks/manager\";\nimport { getEnvironmentVariable } from \"@langchain/core/utils/env\";\n\nexport type MoonshotMessageRole = \"system\" | \"assistant\" | \"user\";\n\ninterface MoonshotMessage {\n  role: MoonshotMessageRole;\n  content: string;\n}\n\n/**\n * Interface representing a request for a chat completion.\n *\n * See https://platform.moonshot.cn/docs/intro#%E6%A8%A1%E5%9E%8B%E5%88%97%E8%A1%A8\n */\ntype ModelName =\n  | (string & NonNullable<unknown>)\n  | \"moonshot-v1-8k\" // context size: 8k\n  | \"moonshot-v1-32k\" // context size: 32k\n  | \"moonshot-v1-128k\"; // context size: 128k\ninterface ChatCompletionRequest {\n  model: ModelName;\n  messages?: MoonshotMessage[];\n  stream?: boolean;\n  max_tokens?: number | null;\n  top_p?: number | null;\n  temperature?: number | null;\n  stop?: string[];\n  presence_penalty?: number;\n  frequency_penalty?: number;\n  n?: number;\n}\n\ninterface BaseResponse {\n  code?: string;\n  message?: string;\n}\n\ninterface ChoiceMessage {\n  role: string;\n  content: string;\n}\n\ninterface ResponseChoice {\n  index: number;\n  finish_reason: \"stop\" | \"length\" | \"null\" | null;\n  delta: ChoiceMessage;\n  message: ChoiceMessage;\n}\n\n/**\n * Interface representing a response from a chat completion.\n */\ninterface ChatCompletionResponse extends BaseResponse {\n  choices: ResponseChoice[];\n  created: number;\n  id: string;\n  model: string;\n  request_id: string;\n  usage: {\n    completion_tokens: number;\n    prompt_tokens: number;\n    total_tokens: number;\n  };\n  output: {\n    text: string;\n    finish_reason: \"stop\" | \"length\" | \"null\" | null;\n  };\n}\n\n/**\n * Interface defining the input to the MoonshotChatInput class.\n */\nexport interface ChatMoonshotParams {\n  /**\n   * @default \"moonshot-v1-8k\"\n   * Alias for `model`\n   */\n  modelName: ModelName;\n  /**\n   * @default \"moonshot-v1-8k\"\n   */\n  model: ModelName;\n\n  /** Whether to stream the results or not. Defaults to false. */\n  streaming?: boolean;\n\n  /** Messages to pass as a prefix to the prompt */\n  messages?: MoonshotMessage[];\n\n  /**\n   * API key to use when making requests. Defaults to the value of\n   * `MOONSHOT_API_KEY` environment variable.\n   */\n  apiKey?: string;\n\n  /**\n   * Amount of randomness injected into the response. Ranges\n   * from 0 to 1 (0 is not included). Use temp closer to 0 for analytical /\n   * multiple choice, and temp closer to 1 for creative and generative tasks.\n   * Defaults to 0, recommended 0.3\n   */\n  temperature?: number;\n\n  /**\n   * Total probability mass of tokens to consider at each step. Range\n   * from 0 to 1. Defaults to 1\n   */\n  topP?: number;\n\n  /**\n   * Different models have different maximum values. For example, the maximum\n   * value of moonshot-v1-8k is 8192. Defaults to 1024\n   */\n  maxTokens?: number;\n\n  stop?: string[];\n\n  /**\n   * There is a penalty, a number between -2.0 and 2.0. Positive values\n   * penalize the newly generated words based on whether they appear in the\n   * text, increasing the likelihood that the model will discuss new topics.\n   * The default value is 0\n   */\n  presencePenalty?: number;\n\n  /**\n   * Frequency penalty, a number between -2.0 and 2.0. Positive values\n   * penalize the newly generated words based on their existing frequency in the\n   * text, making the model less likely to repeat the same words verbatim.\n   * The default value is 0\n   */\n  frequencyPenalty?: number;\n\n  /**\n   * The default value is 1 and cannot be greater than 5. In particular,\n   * when temperature is very small and close to 0, we can only return 1 result.\n   * If n is already set and > 1, Moonshot will return an invalid input parameter\n   * (invalid_request_error).\n   */\n  n?: number;\n}\n\nfunction messageToRole(message: BaseMessage): MoonshotMessageRole {\n  const type = message._getType();\n  switch (type) {\n    case \"ai\":\n      return \"assistant\";\n    case \"human\":\n      return \"user\";\n    case \"system\":\n      return \"system\";\n    case \"function\":\n      throw new Error(\"Function messages not supported yet\");\n    case \"generic\": {\n      if (!ChatMessage.isInstance(message)) {\n        throw new Error(\"Invalid generic chat message\");\n      }\n      if ([\"system\", \"assistant\", \"user\"].includes(message.role)) {\n        return message.role as MoonshotMessageRole;\n      }\n      throw new Error(`Unknown message type: ${type}`);\n    }\n    default:\n      throw new Error(`Unknown message type: ${type}`);\n  }\n}\n\nexport class ChatMoonshot extends BaseChatModel implements ChatMoonshotParams {\n  static lc_name() {\n    return \"ChatMoonshot\";\n  }\n\n  get callKeys() {\n    return [\"stop\", \"signal\", \"options\"];\n  }\n\n  get lc_secrets() {\n    return {\n      apiKey: \"MOONSHOT_API_KEY\",\n    };\n  }\n\n  get lc_aliases() {\n    return undefined;\n  }\n\n  apiKey?: string;\n\n  streaming: boolean;\n\n  messages?: MoonshotMessage[];\n\n  modelName: ChatCompletionRequest[\"model\"];\n\n  model: ChatCompletionRequest[\"model\"];\n\n  apiUrl: string;\n\n  maxTokens?: number | undefined;\n\n  temperature?: number | undefined;\n\n  topP?: number | undefined;\n\n  stop?: string[];\n\n  presencePenalty?: number;\n\n  frequencyPenalty?: number;\n\n  n?: number;\n\n  constructor(fields: Partial<ChatMoonshotParams> & BaseChatModelParams = {}) {\n    super(fields);\n\n    this.apiKey = fields?.apiKey ?? getEnvironmentVariable(\"MOONSHOT_API_KEY\");\n\n    if (!this.apiKey) {\n      throw new Error(\"Moonshot API key not found\");\n    }\n\n    this.apiUrl = \"https://api.moonshot.cn/v1/chat/completions\";\n    this.streaming = fields.streaming ?? false;\n    this.messages = fields.messages ?? [];\n    this.temperature = fields.temperature ?? 0;\n    this.topP = fields.topP ?? 1;\n    this.stop = fields.stop;\n    this.maxTokens = fields.maxTokens;\n    this.modelName = fields?.model ?? fields.modelName ?? \"moonshot-v1-8k\";\n    this.model = this.modelName;\n    this.presencePenalty = fields.presencePenalty ?? 0;\n    this.frequencyPenalty = fields.frequencyPenalty ?? 0;\n    this.n = fields.n ?? 1;\n  }\n\n  /**\n   * Get the parameters used to invoke the model\n   */\n  invocationParams(): Omit<ChatCompletionRequest, \"messages\"> {\n    return {\n      model: this.model,\n      stream: this.streaming,\n      temperature: this.temperature,\n      top_p: this.topP,\n      max_tokens: this.maxTokens,\n      stop: this.stop,\n      presence_penalty: this.presencePenalty,\n      frequency_penalty: this.frequencyPenalty,\n      n: this.n,\n    };\n  }\n\n  /**\n   * Get the identifying parameters for the model\n   */\n  identifyingParams(): Omit<ChatCompletionRequest, \"messages\"> {\n    return this.invocationParams();\n  }\n\n  /** @ignore */\n  async _generate(\n    messages: BaseMessage[],\n    options?: this[\"ParsedCallOptions\"],\n    runManager?: CallbackManagerForLLMRun\n  ): Promise<ChatResult> {\n    const parameters = this.invocationParams();\n\n    const messagesMapped: MoonshotMessage[] = messages.map((message) => ({\n      role: messageToRole(message),\n      content: message.content as string,\n    }));\n\n    const data = parameters.stream\n      ? await new Promise<ChatCompletionResponse>((resolve, reject) => {\n          let response: ChatCompletionResponse;\n          let rejected = false;\n          let resolved = false;\n          this.completionWithRetry(\n            {\n              ...parameters,\n              messages: messagesMapped,\n            },\n            true,\n            options?.signal,\n            (event) => {\n              const data: ChatCompletionResponse = JSON.parse(event.data);\n              if (data?.code) {\n                if (rejected) {\n                  return;\n                }\n                rejected = true;\n                reject(new Error(data?.message));\n                return;\n              }\n\n              const { delta, finish_reason } = data.choices[0];\n              const text = delta.content;\n\n              if (!response) {\n                response = {\n                  ...data,\n                  output: { text, finish_reason },\n                };\n              } else {\n                response.output.text += text;\n                response.output.finish_reason = finish_reason;\n                response.usage = data.usage;\n              }\n\n              // eslint-disable-next-line no-void\n              void runManager?.handleLLMNewToken(text ?? \"\");\n              if (finish_reason && finish_reason !== \"null\") {\n                if (resolved || rejected) return;\n                resolved = true;\n                resolve(response);\n              }\n            }\n          ).catch((error) => {\n            if (!rejected) {\n              rejected = true;\n              reject(error);\n            }\n          });\n        })\n      : await this.completionWithRetry(\n          {\n            ...parameters,\n            messages: messagesMapped,\n          },\n          false,\n          options?.signal\n        ).then<ChatCompletionResponse>((data) => {\n          if (data?.code) {\n            throw new Error(data?.message);\n          }\n          const { finish_reason, message } = data.choices[0];\n          const text = message.content;\n          return {\n            ...data,\n            output: { text, finish_reason },\n          };\n        });\n\n    const {\n      prompt_tokens = 0,\n      completion_tokens = 0,\n      total_tokens = 0,\n    } = data.usage ?? {};\n\n    const { text } = data.output;\n\n    return {\n      generations: [\n        {\n          text,\n          message: new AIMessage(text),\n        },\n      ],\n      llmOutput: {\n        tokenUsage: {\n          promptTokens: prompt_tokens,\n          completionTokens: completion_tokens,\n          totalTokens: total_tokens,\n        },\n      },\n    };\n  }\n\n  /** @ignore */\n  async completionWithRetry(\n    request: ChatCompletionRequest,\n    stream: boolean,\n    signal?: AbortSignal,\n    onmessage?: (event: MessageEvent) => void\n  ) {\n    const makeCompletionRequest = async () => {\n      const response = await fetch(this.apiUrl, {\n        method: \"POST\",\n        headers: {\n          ...(stream ? { Accept: \"text/event-stream\" } : {}),\n          Authorization: `Bearer ${this.apiKey}`,\n          \"Content-Type\": \"application/json\",\n        },\n        body: JSON.stringify(request),\n        signal,\n      });\n\n      if (!stream) {\n        return response.json();\n      }\n\n      if (response.body) {\n        // response will not be a stream if an error occurred\n        if (\n          !response.headers.get(\"content-type\")?.startsWith(\"text/event-stream\")\n        ) {\n          onmessage?.(\n            new MessageEvent(\"message\", {\n              data: await response.text(),\n            })\n          );\n          return;\n        }\n        const reader = response.body.getReader();\n        const decoder = new TextDecoder(\"utf-8\");\n        let data = \"\";\n        let continueReading = true;\n        while (continueReading) {\n          const { done, value } = await reader.read();\n          if (done) {\n            continueReading = false;\n            break;\n          }\n          data += decoder.decode(value);\n          let continueProcessing = true;\n          while (continueProcessing) {\n            const newlineIndex = data.indexOf(\"\\n\");\n            if (newlineIndex === -1) {\n              continueProcessing = false;\n              break;\n            }\n            const line = data.slice(0, newlineIndex);\n            data = data.slice(newlineIndex + 1);\n            if (line.startsWith(\"data:\")) {\n              const value = line.slice(\"data:\".length).trim();\n              if (value === \"[DONE]\") {\n                continueReading = false;\n                break;\n              }\n              const event = new MessageEvent(\"message\", { data: value });\n              onmessage?.(event);\n            }\n          }\n        }\n      }\n    };\n\n    return this.caller.call(makeCompletionRequest);\n  }\n\n  _llmType(): string {\n    return \"moonshot\";\n  }\n\n  /** @ignore */\n  _combineLLMOutput() {\n    return [];\n  }\n}\n"],"mappings":";;;;;;;AAyJA,SAAS,cAAc,SAA2C;CAChE,MAAM,OAAO,QAAQ,UAAU;AAC/B,SAAQ,MAAR;EACE,KAAK,KACH,QAAO;EACT,KAAK,QACH,QAAO;EACT,KAAK,SACH,QAAO;EACT,KAAK,WACH,OAAM,IAAI,MAAM,sCAAsC;EACxD,KAAK;AACH,OAAI,CAAC,YAAY,WAAW,QAAQ,CAClC,OAAM,IAAI,MAAM,+BAA+B;AAEjD,OAAI;IAAC;IAAU;IAAa;IAAO,CAAC,SAAS,QAAQ,KAAK,CACxD,QAAO,QAAQ;AAEjB,SAAM,IAAI,MAAM,yBAAyB,OAAO;EAElD,QACE,OAAM,IAAI,MAAM,yBAAyB,OAAO;;;AAItD,IAAa,eAAb,cAAkC,cAA4C;CAC5E,OAAO,UAAU;AACf,SAAO;;CAGT,IAAI,WAAW;AACb,SAAO;GAAC;GAAQ;GAAU;GAAU;;CAGtC,IAAI,aAAa;AACf,SAAO,EACL,QAAQ,oBACT;;CAGH,IAAI,aAAa;CAIjB;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA;CAEA,YAAY,SAA4D,EAAE,EAAE;AAC1E,QAAM,OAAO;AAEb,OAAK,SAAS,QAAQ,UAAU,uBAAuB,mBAAmB;AAE1E,MAAI,CAAC,KAAK,OACR,OAAM,IAAI,MAAM,6BAA6B;AAG/C,OAAK,SAAS;AACd,OAAK,YAAY,OAAO,aAAa;AACrC,OAAK,WAAW,OAAO,YAAY,EAAE;AACrC,OAAK,cAAc,OAAO,eAAe;AACzC,OAAK,OAAO,OAAO,QAAQ;AAC3B,OAAK,OAAO,OAAO;AACnB,OAAK,YAAY,OAAO;AACxB,OAAK,YAAY,QAAQ,SAAS,OAAO,aAAa;AACtD,OAAK,QAAQ,KAAK;AAClB,OAAK,kBAAkB,OAAO,mBAAmB;AACjD,OAAK,mBAAmB,OAAO,oBAAoB;AACnD,OAAK,IAAI,OAAO,KAAK;;;;;CAMvB,mBAA4D;AAC1D,SAAO;GACL,OAAO,KAAK;GACZ,QAAQ,KAAK;GACb,aAAa,KAAK;GAClB,OAAO,KAAK;GACZ,YAAY,KAAK;GACjB,MAAM,KAAK;GACX,kBAAkB,KAAK;GACvB,mBAAmB,KAAK;GACxB,GAAG,KAAK;GACT;;;;;CAMH,oBAA6D;AAC3D,SAAO,KAAK,kBAAkB;;;CAIhC,MAAM,UACJ,UACA,SACA,YACqB;EACrB,MAAM,aAAa,KAAK,kBAAkB;EAE1C,MAAM,iBAAoC,SAAS,KAAK,aAAa;GACnE,MAAM,cAAc,QAAQ;GAC5B,SAAS,QAAQ;GAClB,EAAE;EAEH,MAAM,OAAO,WAAW,SACpB,MAAM,IAAI,SAAiC,SAAS,WAAW;GAC7D,IAAI;GACJ,IAAI,WAAW;GACf,IAAI,WAAW;AACf,QAAK,oBACH;IACE,GAAG;IACH,UAAU;IACX,EACD,MACA,SAAS,SACR,UAAU;IACT,MAAM,OAA+B,KAAK,MAAM,MAAM,KAAK;AAC3D,QAAI,MAAM,MAAM;AACd,SAAI,SACF;AAEF,gBAAW;AACX,YAAO,IAAI,MAAM,MAAM,QAAQ,CAAC;AAChC;;IAGF,MAAM,EAAE,OAAO,kBAAkB,KAAK,QAAQ;IAC9C,MAAM,OAAO,MAAM;AAEnB,QAAI,CAAC,SACH,YAAW;KACT,GAAG;KACH,QAAQ;MAAE;MAAM;MAAe;KAChC;SACI;AACL,cAAS,OAAO,QAAQ;AACxB,cAAS,OAAO,gBAAgB;AAChC,cAAS,QAAQ,KAAK;;AAIxB,IAAK,YAAY,kBAAkB,QAAQ,GAAG;AAC9C,QAAI,iBAAiB,kBAAkB,QAAQ;AAC7C,SAAI,YAAY,SAAU;AAC1B,gBAAW;AACX,aAAQ,SAAS;;KAGtB,CAAC,OAAO,UAAU;AACjB,QAAI,CAAC,UAAU;AACb,gBAAW;AACX,YAAO,MAAM;;KAEf;IACF,GACF,MAAM,KAAK,oBACT;GACE,GAAG;GACH,UAAU;GACX,EACD,OACA,SAAS,OACV,CAAC,MAA8B,SAAS;AACvC,OAAI,MAAM,KACR,OAAM,IAAI,MAAM,MAAM,QAAQ;GAEhC,MAAM,EAAE,eAAe,YAAY,KAAK,QAAQ;GAChD,MAAM,OAAO,QAAQ;AACrB,UAAO;IACL,GAAG;IACH,QAAQ;KAAE;KAAM;KAAe;IAChC;IACD;EAEN,MAAM,EACJ,gBAAgB,GAChB,oBAAoB,GACpB,eAAe,MACb,KAAK,SAAS,EAAE;EAEpB,MAAM,EAAE,SAAS,KAAK;AAEtB,SAAO;GACL,aAAa,CACX;IACE;IACA,SAAS,IAAI,UAAU,KAAK;IAC7B,CACF;GACD,WAAW,EACT,YAAY;IACV,cAAc;IACd,kBAAkB;IAClB,aAAa;IACd,EACF;GACF;;;CAIH,MAAM,oBACJ,SACA,QACA,QACA,WACA;EACA,MAAM,wBAAwB,YAAY;GACxC,MAAM,WAAW,MAAM,MAAM,KAAK,QAAQ;IACxC,QAAQ;IACR,SAAS;KACP,GAAI,SAAS,EAAE,QAAQ,qBAAqB,GAAG,EAAE;KACjD,eAAe,UAAU,KAAK;KAC9B,gBAAgB;KACjB;IACD,MAAM,KAAK,UAAU,QAAQ;IAC7B;IACD,CAAC;AAEF,OAAI,CAAC,OACH,QAAO,SAAS,MAAM;AAGxB,OAAI,SAAS,MAAM;AAEjB,QACE,CAAC,SAAS,QAAQ,IAAI,eAAe,EAAE,WAAW,oBAAoB,EACtE;AACA,iBACE,IAAI,aAAa,WAAW,EAC1B,MAAM,MAAM,SAAS,MAAM,EAC5B,CAAC,CACH;AACD;;IAEF,MAAM,SAAS,SAAS,KAAK,WAAW;IACxC,MAAM,UAAU,IAAI,YAAY,QAAQ;IACxC,IAAI,OAAO;IACX,IAAI,kBAAkB;AACtB,WAAO,iBAAiB;KACtB,MAAM,EAAE,MAAM,UAAU,MAAM,OAAO,MAAM;AAC3C,SAAI,MAAM;AACR,wBAAkB;AAClB;;AAEF,aAAQ,QAAQ,OAAO,MAAM;KAC7B,IAAI,qBAAqB;AACzB,YAAO,oBAAoB;MACzB,MAAM,eAAe,KAAK,QAAQ,KAAK;AACvC,UAAI,iBAAiB,IAAI;AACvB,4BAAqB;AACrB;;MAEF,MAAM,OAAO,KAAK,MAAM,GAAG,aAAa;AACxC,aAAO,KAAK,MAAM,eAAe,EAAE;AACnC,UAAI,KAAK,WAAW,QAAQ,EAAE;OAC5B,MAAM,QAAQ,KAAK,MAAM,EAAe,CAAC,MAAM;AAC/C,WAAI,UAAU,UAAU;AACtB,0BAAkB;AAClB;;OAEF,MAAM,QAAQ,IAAI,aAAa,WAAW,EAAE,MAAM,OAAO,CAAC;AAC1D,mBAAY,MAAM;;;;;;AAO5B,SAAO,KAAK,OAAO,KAAK,sBAAsB;;CAGhD,WAAmB;AACjB,SAAO;;;CAIT,oBAAoB;AAClB,SAAO,EAAE"}