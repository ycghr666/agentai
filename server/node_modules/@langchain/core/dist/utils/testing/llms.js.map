{"version":3,"file":"llms.js","names":[],"sources":["../../../src/utils/testing/llms.ts"],"sourcesContent":["import { CallbackManagerForLLMRun } from \"../../callbacks/manager.js\";\nimport { BaseLLMParams, LLM } from \"../../language_models/llms.js\";\nimport { GenerationChunk } from \"../../outputs.js\";\n\nexport class FakeLLM extends LLM {\n  response?: string;\n\n  thrownErrorString?: string;\n\n  constructor(\n    fields: { response?: string; thrownErrorString?: string } & BaseLLMParams\n  ) {\n    super(fields);\n    this.response = fields.response;\n    this.thrownErrorString = fields.thrownErrorString;\n  }\n\n  _llmType() {\n    return \"fake\";\n  }\n\n  async _call(\n    prompt: string,\n    _options: this[\"ParsedCallOptions\"],\n    runManager?: CallbackManagerForLLMRun\n  ): Promise<string> {\n    if (this.thrownErrorString) {\n      throw new Error(this.thrownErrorString);\n    }\n    const response = this.response ?? prompt;\n    await runManager?.handleLLMNewToken(response);\n    return response;\n  }\n}\n\nexport class FakeStreamingLLM extends LLM {\n  sleep?: number = 50;\n\n  responses?: string[];\n\n  thrownErrorString?: string;\n\n  constructor(\n    fields: {\n      sleep?: number;\n      responses?: string[];\n      thrownErrorString?: string;\n    } & BaseLLMParams\n  ) {\n    super(fields);\n    this.sleep = fields.sleep ?? this.sleep;\n    this.responses = fields.responses;\n    this.thrownErrorString = fields.thrownErrorString;\n  }\n\n  _llmType() {\n    return \"fake\";\n  }\n\n  async _call(prompt: string): Promise<string> {\n    if (this.thrownErrorString) {\n      throw new Error(this.thrownErrorString);\n    }\n    const response = this.responses?.[0];\n    this.responses = this.responses?.slice(1);\n    return response ?? prompt;\n  }\n\n  async *_streamResponseChunks(\n    input: string,\n    _options?: this[\"ParsedCallOptions\"],\n    runManager?: CallbackManagerForLLMRun\n  ) {\n    if (this.thrownErrorString) {\n      throw new Error(this.thrownErrorString);\n    }\n    const response = this.responses?.[0];\n    this.responses = this.responses?.slice(1);\n    for (const c of response ?? input) {\n      await new Promise((resolve) => setTimeout(resolve, this.sleep));\n      yield { text: c, generationInfo: {} } as GenerationChunk;\n      await runManager?.handleLLMNewToken(c);\n    }\n  }\n}\n"],"mappings":";;;AAIA,IAAa,UAAb,cAA6B,IAAI;CAC/B;CAEA;CAEA,YACE,QACA;AACA,QAAM,OAAO;AACb,OAAK,WAAW,OAAO;AACvB,OAAK,oBAAoB,OAAO;;CAGlC,WAAW;AACT,SAAO;;CAGT,MAAM,MACJ,QACA,UACA,YACiB;AACjB,MAAI,KAAK,kBACP,OAAM,IAAI,MAAM,KAAK,kBAAkB;EAEzC,MAAM,WAAW,KAAK,YAAY;AAClC,QAAM,YAAY,kBAAkB,SAAS;AAC7C,SAAO;;;AAIX,IAAa,mBAAb,cAAsC,IAAI;CACxC,QAAiB;CAEjB;CAEA;CAEA,YACE,QAKA;AACA,QAAM,OAAO;AACb,OAAK,QAAQ,OAAO,SAAS,KAAK;AAClC,OAAK,YAAY,OAAO;AACxB,OAAK,oBAAoB,OAAO;;CAGlC,WAAW;AACT,SAAO;;CAGT,MAAM,MAAM,QAAiC;AAC3C,MAAI,KAAK,kBACP,OAAM,IAAI,MAAM,KAAK,kBAAkB;EAEzC,MAAM,WAAW,KAAK,YAAY;AAClC,OAAK,YAAY,KAAK,WAAW,MAAM,EAAE;AACzC,SAAO,YAAY;;CAGrB,OAAO,sBACL,OACA,UACA,YACA;AACA,MAAI,KAAK,kBACP,OAAM,IAAI,MAAM,KAAK,kBAAkB;EAEzC,MAAM,WAAW,KAAK,YAAY;AAClC,OAAK,YAAY,KAAK,WAAW,MAAM,EAAE;AACzC,OAAK,MAAM,KAAK,YAAY,OAAO;AACjC,SAAM,IAAI,SAAS,YAAY,WAAW,SAAS,KAAK,MAAM,CAAC;AAC/D,SAAM;IAAE,MAAM;IAAG,gBAAgB,EAAE;IAAE;AACrC,SAAM,YAAY,kBAAkB,EAAE"}