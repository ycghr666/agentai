{"version":3,"file":"refine_prompts.js","names":[],"sources":["../../../src/chains/question_answering/refine_prompts.ts"],"sourcesContent":["import {\n  PromptTemplate,\n  ChatPromptTemplate,\n  SystemMessagePromptTemplate,\n  HumanMessagePromptTemplate,\n  AIMessagePromptTemplate,\n} from \"@langchain/core/prompts\";\nimport {\n  ConditionalPromptSelector,\n  isChatModel,\n} from \"@langchain/core/example_selectors\";\n\nexport const DEFAULT_REFINE_PROMPT_TMPL = `The original question is as follows: {question}\nWe have provided an existing answer: {existing_answer}\nWe have the opportunity to refine the existing answer\n(only if needed) with some more context below.\n------------\n{context}\n------------\nGiven the new context, refine the original answer to better answer the question. \nIf the context isn't useful, return the original answer.`;\nexport const DEFAULT_REFINE_PROMPT = /*#__PURE__*/ new PromptTemplate({\n  inputVariables: [\"question\", \"existing_answer\", \"context\"],\n  template: DEFAULT_REFINE_PROMPT_TMPL,\n});\n\nconst refineTemplate = `The original question is as follows: {question}\nWe have provided an existing answer: {existing_answer}\nWe have the opportunity to refine the existing answer\n(only if needed) with some more context below.\n------------\n{context}\n------------\nGiven the new context, refine the original answer to better answer the question. \nIf the context isn't useful, return the original answer.`;\n\nconst messages = [\n  /*#__PURE__*/ HumanMessagePromptTemplate.fromTemplate(\"{question}\"),\n  /*#__PURE__*/ AIMessagePromptTemplate.fromTemplate(\"{existing_answer}\"),\n  /*#__PURE__*/ HumanMessagePromptTemplate.fromTemplate(refineTemplate),\n];\n\nexport const CHAT_REFINE_PROMPT =\n  /*#__PURE__*/ ChatPromptTemplate.fromMessages(messages);\n\nexport const REFINE_PROMPT_SELECTOR =\n  /*#__PURE__*/ new ConditionalPromptSelector(DEFAULT_REFINE_PROMPT, [\n    [isChatModel, CHAT_REFINE_PROMPT],\n  ]);\n\nexport const DEFAULT_TEXT_QA_PROMPT_TMPL = `Context information is below. \n---------------------\n{context}\n---------------------\nGiven the context information and no prior knowledge, answer the question: {question}`;\nexport const DEFAULT_TEXT_QA_PROMPT = /*#__PURE__*/ new PromptTemplate({\n  inputVariables: [\"context\", \"question\"],\n  template: DEFAULT_TEXT_QA_PROMPT_TMPL,\n});\n\nconst chat_qa_prompt_template = `Context information is below. \n---------------------\n{context}\n---------------------\nGiven the context information and no prior knowledge, answer any questions`;\nconst chat_messages = [\n  /*#__PURE__*/ SystemMessagePromptTemplate.fromTemplate(\n    chat_qa_prompt_template\n  ),\n  /*#__PURE__*/ HumanMessagePromptTemplate.fromTemplate(\"{question}\"),\n];\nexport const CHAT_QUESTION_PROMPT =\n  /*#__PURE__*/ ChatPromptTemplate.fromMessages(chat_messages);\nexport const QUESTION_PROMPT_SELECTOR =\n  /*#__PURE__*/ new ConditionalPromptSelector(DEFAULT_TEXT_QA_PROMPT, [\n    [isChatModel, CHAT_QUESTION_PROMPT],\n  ]);\n"],"mappings":";;;;AAYA,MAAa,6BAA6B;;;;;;;;;AAS1C,MAAa,wCAAsC,IAAI,eAAe;CACpE,gBAAgB;EAAC;EAAY;EAAmB;EAAU;CAC1D,UAAU;CACX,CAAC;AAYF,MAAM,WAAW;CACD,2CAA2B,aAAa,aAAa;CACrD,wCAAwB,aAAa,oBAAoB;CACzD,2CAA2B,aAbpB;;;;;;;;0DAagD;CACtE;AAED,MAAa,qBACG,mCAAmB,aAAa,SAAS;AAEzD,MAAa,yCACG,IAAI,0BAA0B,uBAAuB,CACjE,CAAC,aAAa,mBAAmB,CAClC,CAAC;AAEJ,MAAa,8BAA8B;;;;;AAK3C,MAAa,yCAAuC,IAAI,eAAe;CACrE,gBAAgB,CAAC,WAAW,WAAW;CACvC,UAAU;CACX,CAAC;AAOF,MAAM,gBAAgB,CACN,4CAA4B,aANZ;;;;4EAQ7B,EACa,2CAA2B,aAAa,aAAa,CACpE;AACD,MAAa,uBACG,mCAAmB,aAAa,cAAc;AAC9D,MAAa,2CACG,IAAI,0BAA0B,wBAAwB,CAClE,CAAC,aAAa,qBAAqB,CACpC,CAAC"}